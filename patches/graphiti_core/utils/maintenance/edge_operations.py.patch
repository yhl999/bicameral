diff --git a/graphiti_core/utils/maintenance/edge_operations.py b/graphiti_core/utils/maintenance/edge_operations.py
index 18e384e..b9f4166 100644
--- a/graphiti_core/utils/maintenance/edge_operations.py
+++ b/graphiti_core/utils/maintenance/edge_operations.py
@@ -15,8 +15,11 @@ limitations under the License.
 """
 
 import logging
+import re
 from datetime import datetime
+from difflib import SequenceMatcher
 from time import time
+from typing import Literal
 
 from pydantic import BaseModel
 from typing_extensions import LiteralString
@@ -46,6 +49,175 @@ from graphiti_core.utils.maintenance.dedup_helpers import _normalize_string_exac
 
 logger = logging.getLogger(__name__)
 
+# ---------------------------------------------------------------------------
+# constrained_soft enforcement helpers
+# ---------------------------------------------------------------------------
+
+# Generic connector relation types that carry no domain-specific signal.
+# In constrained_soft mode, edges with these relation_types that have no
+# ontology match are dropped after LLM extraction.
+# All names are stored in SCREAMING_SNAKE_CASE; comparison uses normalized form
+# so mixed-case / spaced variants from the LLM (e.g. 'relates to') are caught.
+_GENERIC_EDGE_NAMES: frozenset[str] = frozenset({
+    'RELATES_TO',
+    'IS_RELATED_TO',
+    'IS_RELATED',
+    'MENTIONS',
+    'CONNECTED_TO',
+    'ASSOCIATED_WITH',
+    'HAS',
+    'CONTAINS',
+    'INCLUDES',
+    'LINKS_TO',
+    'REFERENCES',
+    'IS_CONNECTED_TO',
+    'IS_ASSOCIATED_WITH',
+})
+
+# Similarity threshold for near-miss canonicalization.
+# A relation_type that scores ≥ this against any ontology name is snapped to that name.
+_CANONICALIZE_THRESHOLD: float = 0.78
+
+
+def _normalize_relation_type(relation_type: str) -> str:
+    """Normalize a relation type string to SCREAMING_SNAKE_CASE for comparison.
+
+    Performs these transforms in order:
+    1. Strip surrounding whitespace.
+    2. Replace ANY non-alphanumeric character (spaces, hyphens, dots, carets,
+       colons, etc.) with an underscore — closes punctuation-bypass vectors
+       like ``'RELATES^TO'`` or ``'MENTIONS.'``.
+    3. Collapse runs of consecutive underscores to a single underscore.
+    4. Trim leading/trailing underscores left by step 2.
+    5. Uppercase everything.
+
+    This ensures that LLM outputs like ``'relates_to'``, ``'Relates To'``,
+    ``'relates-to'``, ``'RELATES^TO'``, or ``'MENTIONS.'`` all compare equal
+    to the canonical ``'RELATES_TO'`` / ``'MENTIONS'`` entry in the ontology /
+    noise filter, without requiring an exact-case match.
+    """
+    s = relation_type.strip()
+    s = re.sub(r'[^a-zA-Z0-9]+', '_', s)   # any non-alnum → underscore
+    s = re.sub(r'_+', '_', s)               # collapse repeated underscores
+    s = s.strip('_')                         # trim leading/trailing underscores
+    return s.upper()
+
+
+def _canonicalize_edge_name(
+    relation_type: str,
+    ontology_names: frozenset[str],
+    threshold: float = _CANONICALIZE_THRESHOLD,
+) -> str:
+    """Snap a near-miss relation_type to the closest ontology name.
+
+    Normalizes the input to SCREAMING_SNAKE_CASE before comparison so that
+    LLM variants with different casing or separators are handled consistently.
+    If the best similarity ratio is below *threshold*, returns the *normalized*
+    form of the original (not an ontology name).  Only exact-match or
+    high-similarity (≥ threshold) names are canonicalised.
+
+    A negation polarity guard prevents canonicalization from flipping the
+    semantic polarity: a ``NOT_*`` relation will never be snapped to a non-
+    ``NOT_*`` ontology name (and vice versa).
+
+    Parameters
+    ----------
+    relation_type:
+        The relation type string returned by the LLM.
+    ontology_names:
+        Set of canonical relation type names from the lane ontology.
+    threshold:
+        Minimum SequenceMatcher ratio to accept a canonicalisation.
+
+    Returns
+    -------
+    str
+        Canonical ontology name if a close match exists; otherwise the
+        normalized (SCREAMING_SNAKE_CASE) form of the original input.
+    """
+    # Normalize first — ensures consistent casing for all subsequent comparisons.
+    normalized = _normalize_relation_type(relation_type)
+
+    if not ontology_names or normalized in ontology_names:
+        # Exact match after normalization (or no ontology to check).
+        if normalized != relation_type:
+            logger.info(
+                'constrained_soft: canonicalized edge %r → %r (normalization)',
+                relation_type,
+                normalized,
+            )
+        return normalized
+
+    best_name = normalized
+    best_ratio = 0.0
+    for canonical in ontology_names:
+        ratio = SequenceMatcher(None, normalized, canonical).ratio()
+        if ratio > best_ratio:
+            best_ratio = ratio
+            best_name = canonical
+
+    if best_ratio >= threshold:
+        # Negation polarity guard: never snap across the NOT_ boundary.
+        # e.g., NOT_RELATED_TO must not be canonicalized to RELATED_TO.
+        original_is_negated = normalized.startswith('NOT_')
+        candidate_is_negated = best_name.startswith('NOT_')
+        if original_is_negated != candidate_is_negated:
+            logger.debug(
+                'constrained_soft: polarity guard blocked %r → %r (NOT_ boundary mismatch)',
+                normalized,
+                best_name,
+            )
+            return normalized  # keep normalized form; do not flip polarity
+
+        if best_name != relation_type:
+            logger.info(
+                'constrained_soft: canonicalized edge %r → %r (ratio=%.2f)',
+                relation_type,
+                best_name,
+                best_ratio,
+            )
+        return best_name
+
+    # No close ontology match — return the normalized form so casing is consistent.
+    return normalized
+
+
+def _should_filter_constrained_edge(
+    relation_type: str,
+    ontology_names: frozenset[str],
+) -> bool:
+    """Return True if an edge should be dropped in constrained_soft mode.
+
+    Drops edges only when ALL of the following hold:
+    - The relation_type is NOT in the ontology (no exact/near-miss match was applied).
+    - The normalized relation_type is a known generic/connector type with no signal.
+
+    Comparison is performed on the normalized (SCREAMING_SNAKE_CASE) form so
+    that mixed-case LLM outputs like ``'relates to'`` or ``'Mentions'`` are
+    caught by the filter even if the caller did not pre-normalize.
+
+    Keeps domain-specific off-ontology edges (they may still carry value).
+
+    Parameters
+    ----------
+    relation_type:
+        Post-canonicalization relation type string (may already be normalized).
+    ontology_names:
+        Set of canonical relation type names from the lane ontology.
+    """
+    # Normalize defensively — callers may pass already-normalized strings, no-op then.
+    normalized = _normalize_relation_type(relation_type)
+
+    if normalized in ontology_names:
+        return False  # ontology match → keep
+    if normalized in _GENERIC_EDGE_NAMES:
+        logger.debug(
+            'constrained_soft: dropping generic off-ontology edge %r',
+            relation_type,
+        )
+        return True  # generic noise → drop
+    return False  # specific off-ontology → allow (limited)
+
 
 def build_episodic_edges(
     entity_nodes: list[EntityNode],
@@ -94,7 +266,18 @@ async def extract_edges(
     group_id: str = '',
     edge_types: dict[str, type[BaseModel]] | None = None,
     custom_extraction_instructions: str | None = None,
+    extraction_mode: str = 'permissive',
 ) -> list[EntityEdge]:
+    """Extract relationship edges from an episode.
+
+    Parameters
+    ----------
+    extraction_mode : str
+        Extraction behaviour: ``'permissive'`` (default — extract broadly) or
+        ``'constrained_soft'`` (ontology-conformant — after LLM extraction,
+        near-miss relation types are canonicalized to ontology names and
+        generic off-ontology noise is dropped).
+    """
     start = time()
 
     extract_edges_max_tokens = 16384
@@ -134,6 +317,7 @@ async def extract_edges(
         'reference_time': episode.valid_at,
         'edge_types': edge_types_context,
         'custom_extraction_instructions': custom_extraction_instructions or '',
+        'extraction_mode': extraction_mode,
     }
 
     llm_response = await llm_client.generate_response(
@@ -168,6 +352,39 @@ async def extract_edges(
 
         edges_data.append(edge_data)
 
+    # -----------------------------------------------------------------------
+    # constrained_soft post-extraction enforcement
+    # -----------------------------------------------------------------------
+    # After entity-name validation, apply two enforcement passes:
+    #   1. Canonicalize near-miss relation types to ontology names.
+    #   2. Filter generic off-ontology noise.
+    # This is intentionally done in code (not prompt) to avoid conflicting
+    # directives and ensure deterministic enforcement regardless of LLM drift.
+    if extraction_mode == 'constrained_soft' and edge_types is not None:
+        ontology_names: frozenset[str] = frozenset(edge_types.keys())
+        enforced: list[ExtractedEdge] = []
+        for edge_data in edges_data:
+            canonical = _canonicalize_edge_name(edge_data.relation_type, ontology_names)
+            edge_data.relation_type = canonical
+            if _should_filter_constrained_edge(canonical, ontology_names):
+                logger.info(
+                    'constrained_soft: dropped generic edge %r between %r → %r',
+                    canonical,
+                    edge_data.source_entity_name,
+                    edge_data.target_entity_name,
+                )
+                continue
+            enforced.append(edge_data)
+        dropped = len(edges_data) - len(enforced)
+        if dropped:
+            logger.info(
+                'constrained_soft enforcement: kept %d/%d edges (dropped %d generic/noise)',
+                len(enforced),
+                len(edges_data),
+                dropped,
+            )
+        edges_data = enforced
+
     end = time()
     logger.debug(f'Extracted {len(edges_data)} new edges in {(end - start) * 1000:.0f} ms')
 
@@ -241,6 +458,7 @@ async def resolve_extracted_edges(
     entities: list[EntityNode],
     edge_types: dict[str, type[BaseModel]],
     edge_type_map: dict[tuple[str, str], list[str]],
+    dedupe_mode: Literal['semantic', 'deterministic'] = 'semantic',
 ) -> tuple[list[EntityEdge], list[EntityEdge], list[EntityEdge]]:
     """Resolve extracted edges against existing graph context.
 
@@ -373,26 +591,47 @@ async def resolve_extracted_edges(
         edge_types_lst.append(extracted_edge_types)
 
     # resolve edges with related edges in the graph and find invalidation candidates
+    # Keep semantic mode call signature backward-compatible for test monkeypatches.
+    if dedupe_mode == 'semantic':
+        resolve_coros = [
+            resolve_extracted_edge(
+                llm_client,
+                extracted_edge,
+                related_edges,
+                existing_edges,
+                episode,
+                extracted_edge_types,
+            )
+            for extracted_edge, related_edges, existing_edges, extracted_edge_types in zip(
+                extracted_edges,
+                related_edges_lists,
+                edge_invalidation_candidates,
+                edge_types_lst,
+                strict=True,
+            )
+        ]
+    else:
+        resolve_coros = [
+            resolve_extracted_edge(
+                llm_client,
+                extracted_edge,
+                related_edges,
+                existing_edges,
+                episode,
+                extracted_edge_types,
+                dedupe_mode=dedupe_mode,
+            )
+            for extracted_edge, related_edges, existing_edges, extracted_edge_types in zip(
+                extracted_edges,
+                related_edges_lists,
+                edge_invalidation_candidates,
+                edge_types_lst,
+                strict=True,
+            )
+        ]
+
     results: list[tuple[EntityEdge, list[EntityEdge], list[EntityEdge]]] = list(
-        await semaphore_gather(
-            *[
-                resolve_extracted_edge(
-                    llm_client,
-                    extracted_edge,
-                    related_edges,
-                    existing_edges,
-                    episode,
-                    extracted_edge_types,
-                )
-                for extracted_edge, related_edges, existing_edges, extracted_edge_types in zip(
-                    extracted_edges,
-                    related_edges_lists,
-                    edge_invalidation_candidates,
-                    edge_types_lst,
-                    strict=True,
-                )
-            ]
-        )
+        await semaphore_gather(*resolve_coros)
     )
 
     resolved_edges: list[EntityEdge] = []
@@ -467,6 +706,7 @@ async def resolve_extracted_edge(
     existing_edges: list[EntityEdge],
     episode: EpisodicNode,
     edge_type_candidates: dict[str, type[BaseModel]] | None = None,
+    dedupe_mode: Literal['semantic', 'deterministic'] = 'semantic',
 ) -> tuple[EntityEdge, list[EntityEdge], list[EntityEdge]]:
     """Resolve an extracted edge against existing graph context.
 
@@ -524,6 +764,36 @@ async def resolve_extracted_edge(
                 resolved.episodes.append(episode.uuid)
             return resolved, [], []
 
+    # Migration-only deterministic dedupe mode:
+    # Skip LLM duplicate/contradiction resolution and keep exact-match-only behavior.
+    # This mode is intended for controlled backfills where semantic dedupe may be unstable.
+    if dedupe_mode == 'deterministic':
+        resolved_edge = extracted_edge
+
+        # Preserve optional structured attribute extraction for allowed edge types.
+        edge_model = edge_type_candidates.get(resolved_edge.name) if edge_type_candidates else None
+        if edge_model is not None and len(edge_model.model_fields) != 0 and episode is not None:
+            edge_attributes_context = {
+                'episode_content': episode.content,
+                'reference_time': episode.valid_at,
+                'fact': resolved_edge.fact,
+            }
+            edge_attributes_response = await llm_client.generate_response(
+                prompt_library.extract_edges.extract_attributes(edge_attributes_context),
+                response_model=edge_model,  # type: ignore
+                model_size=ModelSize.small,
+                prompt_name='extract_edges.extract_attributes',
+            )
+            resolved_edge.attributes = edge_attributes_response
+        else:
+            resolved_edge.attributes = {}
+
+        logger.info(
+            'resolve_extracted_edge: dedupe_mode=deterministic, skipping semantic dedupe for edge %s',
+            resolved_edge.name,
+        )
+        return resolved_edge, [], []
+
     start = time()
 
     # Prepare context for LLM with continuous indexing
@@ -628,7 +898,7 @@ async def resolve_extracted_edge(
 
     end = time()
     logger.debug(
-        f'Resolved Edge: {extracted_edge.uuid} -> {resolved_edge.uuid}, in {(end - start) * 1000} ms'
+        f'Resolved Edge: {extracted_edge.name} is {resolved_edge.name}, in {(end - start) * 1000} ms'
     )
 
     now = utc_now()
